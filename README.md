# NLI-robustness

# Reinforcing Noise Robustness in Natural Language Inference (NLI) Tasks  
*Improving robustness in ELECTRA-based NLI models under noisy conditions*  

##  Overview  
This project explores the impact of noise perturbations on **Natural Language Inference (NLI)** tasks and proposes **inoculation techniques** to improve robustness. Using an **ELECTRA-based model**, we analyze performance degradation under various noise conditions and implement strategies to mitigate the effects, ensuring strong generalization on clean datasets.

##  Key Features  
- **Noise Evaluation**: Analyzes performance-impacting artifacts in NLI models.  
- **Robust Training**: Applies inoculation techniques to enhance model resilience.  
- **Generalization Study**: Ensures model accuracy remains stable on clean datasets.  
